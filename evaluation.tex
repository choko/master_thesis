\chapter{Evaluation}\label{chapter:evaluation}
In order to show that the CloudASR platform is ready for the production usage
  several benchmarks were made.
First, real time factor (RTF) of the batch speech recognition mode was measured and compared with Google Speech API.
Second, latency of the online speech recognition mode was measured.
Finally, number of parallel requests for batch speech recognition mode was measured to show that CloudASR is scalable.


\section{RTF of Batch Speech Recognition}
In the first benchmark RTF of CloudASR batch mode was compared with RTF of Google Speech API
  using test set from the Czech Public Transportation Information Domain \cite{korvas2014vystadial}.
WER and RTF of both APIs were measured with following results:
Google Speech API had 60\% WER and RTF 0.3 whereas
  CloudASR had 22\% WER and RTF 0.22.
Request times of both APIs are displayed in Figure~\ref{fig:batch-benchmark}.

This benchmark shows that RTF of CloudASR batch mode is lower than RTF of Google Speech API.
Moreover, the benchmark shows that the CloudASR platform can achieve better accuracy than Google Speech API on limited domains
  if the used decoding graphs are customized for those domains.


\begin{figure}[h]
  \centering
  \includegraphics[width=0.75\textwidth]{./img/batch.pdf}

  \caption{
    Batch recognition benchmark.
  }
  \label{fig:batch-benchmark}
\end{figure}



\section{Latency of Online Speech Recognition}
In the second benchmark latency of CloudASR online mode was measured.
Low latency is crucial for successful usage of speech recognition in dialogue systems,
  but there are not so many web services that provide online speech recognition mode.
Therefore, support for online speech recognition mode can be seen as a key feature of the CloudASR platform.

The reason why the online speech recognition mode is better suited for dialogue systems is
  that it is possible to get the results while the speech is being recorded.
Thus, dialogue systems can react quickly.
Results, plotted in Figure~\ref{fig:online-benchmark}, show that
  the latency of the online speech recognition mode remains small even for long recordings
  which is in contrast to the increasing latency of the batch speech recognition mode.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.75\textwidth]{./img/online.pdf}

  \caption{
    A latency comparison for CloudASR online and batch mode.
  }
  \label{fig:online-benchmark}
\end{figure}


\section{Parallel Requests Benchmark}
Because the main bottleneck of the CloudASR platform is a number of running workers,
  workers with dummy ASR engine (described in Figure~\ref{fig:dummyasr}) were used to be able to test how many parallel requests can CloudASR handle.
As a result, 1000 dummy workers could run on a Mesos cluster with 5 slaves (4CPU, 16GB RAM).
Also, workload was spread across 5 API containers with a load-balancer.

\begin{figure}[h]
  \verbatiminput{snippets/benchmark.bash}

  \caption{A simple benchmark script that sends 100 parallel requests to the CloudASR API and prints out request time for each request.}
  \label{fig:benchmark}
\end{figure}

Then several benchmarks were run to show how RTF of the batch recognition mode changes with different number of parallel requests.
The platform was tested with a different number of parallel requests (50, 250, 500, 750 and 1000)
  and with files with different lengths (5s, 10s, 20s, 30s, 40s, 50s and 60s).
To be able to run so many parallel requests,
  a simple benchmark, shown in Figure~\ref{fig:benchmark}, was run on 5 machines.
Each machine sent one-fifth of the total number of parallel requests ten times
  and then the average latency was computed across all machines.

Results, summarized in Figure~\ref{fig:parallel-benchmark}, show
  that CloudASR platform adds just a very little overhead compared to the raw dummy worker for small recordings.
But the latency increases rapidly for large recordings with more than 500 parallel requests.
This is probably caused by network capacity of the servers that run the benchmark
  and it should not affect the platform with the real usage.
Moreover, this will not affect the online speech recognition mode because it sends only very small messages.
Therefore, the platform should be able to handle much more parallel requests with appropriate number of workers.

\begin{figure}
  \centering
  \includegraphics[width=0.75\textwidth]{./img/parallel.pdf}

  \caption{
    The graph shows platform \& network latency for recordings with various lengths
      given the number of parallel requests.
  }
  \label{fig:parallel-benchmark}
\end{figure}
